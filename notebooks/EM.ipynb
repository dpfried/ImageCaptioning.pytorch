{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dfried/projects/ImageCaptioning.pytorch\n"
     ]
    }
   ],
   "source": [
    "cd /home/dfried/projects/ImageCaptioning.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/dfried/projects/ImageCaptioning.pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import captioning.utils.opts as opts\n",
    "import captioning.utils.misc as utils\n",
    "import captioning.models as models\n",
    "from captioning.utils import eval_utils\n",
    "from captioning import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captioning.data.dataloader import DataLoader\n",
    "from captioning.data.dataloaderraw import DataLoaderRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "opts.add_eval_options(parser)\n",
    "opts.add_diversity_opts(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=0, beam_size=1, block_trigrams=0, coco_json='', decoding_constraint=0, diversity_lambda=0.5, dump_images=1, dump_json=1, dump_path=0, eval_oracle=1, group_size=1, id='', image_folder='', image_root='', input_att_dir='', input_box_dir='', input_fc_dir='', input_json='', input_label_h5='', language_eval=0, length_penalty='', max_length=20, num_images=-1, remove_bad_endings=0, sample_method='greedy', sample_n=1, sample_n_method='sample', split='test', suppress_UNK=1, temperature=1.0, verbose=1, verbose_beam=1, verbose_captions=0, verbose_loss=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fname = 'log_updown_contrastive_cbs_mlp_soft-em/model-best.pth'\n",
    "infos_fname = 'log_updown_contrastive_cbs_mlp_soft-em/infos_updown_contrastive_cbs_mlp_soft-em-best.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iter', 'epoch', 'loader_state_dict', 'vocab', 'opt', 'best_val_score'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(infos_fname, 'rb') as f:\n",
    "    infos = utils.pickle_load(f)\n",
    "infos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = ['input_fc_dir', 'input_att_dir', 'input_box_dir', 'input_label_h5', 'input_json', 'batch_size', 'id']\n",
    "ignore = ['start_from']\n",
    "\n",
    "for k in vars(infos['opt']).keys():\n",
    "    if k in replace:\n",
    "        setattr(opt, k, getattr(opt, k) or getattr(infos['opt'], k, ''))\n",
    "    elif k not in ignore:\n",
    "        if not k in vars(opt):\n",
    "            vars(opt).update({k: vars(infos['opt'])[k]}) # copy over options from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.vocab = infos['vocab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.setup(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del opt.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpDownModel(\n",
       "  (embed): Sequential(\n",
       "    (0): Embedding(9488, 1000)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc_embed): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (att_embed): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (logit): Linear(in_features=1000, out_features=9488, bias=True)\n",
       "  (ctx2att): Linear(in_features=1000, out_features=512, bias=True)\n",
       "  (distractor_scorer): DistractorScorer(\n",
       "    (scorer): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=200, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (core): UpDownCore(\n",
       "    (att_lstm): LSTMCell(3000, 1000)\n",
       "    (lang_lstm): LSTMCell(2000, 1000)\n",
       "    (attention): Attention(\n",
       "      (h2att): Linear(in_features=1000, out_features=512, bias=True)\n",
       "      (alpha_net): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_fname, map_location='cpu'))\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loading json file:  data/cocotalk.json\n",
      "vocab size is  9487\n",
      "DataLoader loading h5 file:  data/cocotalk_fc data/cocobu_att data/cocotalk_box data/cocotalk_label.h5\n",
      "max sequence length in data is 16\n",
      "read 123287 image features\n",
      "assigned 113287 images to split train\n",
      "assigned 5000 images to split val\n",
      "assigned 5000 images to split test\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(opt, shuffle_override=False, wrap_override=False, build_nearest_neighbor_indices_for_splits=['train'], index_serialization_root_path='data/cocobu_indices/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = loader.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = loader.get_batch('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_captions_from_batch(data):\n",
    "    batch_captions = []\n",
    "    for batch_labels in data['labels']:\n",
    "        instance_captions = []\n",
    "        for img_labels in batch_labels:\n",
    "            neighbor_captions = []\n",
    "            for neighbor_labels in img_labels:\n",
    "                caption = [vocab[str(ix.item())] for ix in neighbor_labels if ix != 0]\n",
    "                neighbor_captions.append(caption)\n",
    "            instance_captions.append(neighbor_captions)\n",
    "        batch_captions.append(instance_captions)\n",
    "    return batch_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_tag(tag, inner):\n",
    "    return f'<{tag}>{inner}</{tag}>'\n",
    "\n",
    "def image_html(image_path, width=300, border=False):\n",
    "    if border:\n",
    "        style = ' style=\"border: 5px solid #0FF\" '\n",
    "    else:\n",
    "        style = ''\n",
    "    return f'<img width={width} src=\"{image_path}\" {style}></img>'\n",
    "\n",
    "def captions_html(captions):\n",
    "    #return wrap_tag('p', '<br>'.join(' '.join(cap) for cap in captions))\n",
    "    return wrap_tag('ol', ''.join(wrap_tag('li', cap) for cap in captions))\n",
    "\n",
    "def images_html(image_paths, width=300, num_per_row=5, target=None, captions=None, titles=None):\n",
    "    rows = []\n",
    "    for ix in range(0, len(image_paths), num_per_row):\n",
    "        items = [wrap_tag('td', image_html(image_paths[image_ix], width=width, border=image_ix == target)) \n",
    "                 for image_ix in range(ix, ix+num_per_row) if image_ix < len(image_paths)]\n",
    "        rows.append(wrap_tag('tr', ''.join(items)))\n",
    "        if titles is not None:\n",
    "            title_html = [\n",
    "                wrap_tag('td', wrap_tag('b', titles[image_ix]))\n",
    "                for image_ix in range(ix, ix+num_per_row)\n",
    "                if image_ix < len(image_paths)\n",
    "            ]\n",
    "            rows.append(wrap_tag('tr', ''.join(title_html)))\n",
    "        if captions is not None:\n",
    "            cap_html = [\n",
    "                wrap_tag('td', captions_html(captions[image_ix]))\n",
    "                for image_ix in range(ix, ix+num_per_row)\n",
    "                if image_ix < len(image_paths)\n",
    "            ]\n",
    "            rows.append(wrap_tag('tr', ''.join(cap_html)))\n",
    "    return wrap_tag('table', ''.join(rows))\n",
    "\n",
    "def display_images(image_paths, width=300, num_per_row=5, target=None, captions=None, titles=None):\n",
    "    display(HTML(images_html(image_paths, width=width, num_per_row=num_per_row, target=target, captions=captions, titles=titles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_batch(img_fc_feat, k, include_self=False, self_ix=None):\n",
    "    assert len(img_fc_feat.shape) == 1, \"should be the features for a single image\"\n",
    "    D, I = index.search(img_fc_feat[None], k)\n",
    "    n_images, k_ = D.shape\n",
    "    assert n_images == 1\n",
    "    indices = []\n",
    "    if include_self:\n",
    "        assert self_ix is not None\n",
    "        indices.append(self_ix)\n",
    "    indices.extend([ixs[i] for i in I.flatten()])\n",
    "    data = [loader.dataset[ix, 0, False] for ix in indices]\n",
    "    batch = loader.dataset.collate_func(data, 'train')\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_neighbors(features, k=5, num_per_row=5):\n",
    "    index = loader.indices['train']\n",
    "    neighbor_batch = index.get_neighbor_batch(loader, features, k)\n",
    "    paths_k = [d['file_path'] for d in neighbor_batch['infos']]\n",
    "    captions_k = [[' '.join(c) for c in ns] for cs in get_captions_from_batch(neighbor_batch) for ns in cs]\n",
    "    display_images(paths_k, captions=captions_k, num_per_row=num_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000250804.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000433662.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000020966.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000063043.jpg\" ></img></td></tr><tr><td><ol><li>bulls dogs and people all share the same street</li><li>a black and white cow standing in a market</li><li>two cows and two small dogs hang out in front a street market</li><li>two cows and two dogs and people at an open air market</li><li>two dogs and two cows are amongst people in a market</li></ol></td><td><ol><li>two people standing next to two huge elephants</li><li>two elephants standing near two people with mountains background</li><li>two elephants in the foreground and people in a dirt field</li><li>3 saddled elephants and people in a dirt field</li><li>there are two people standing near two elephants</li></ol></td><td><ol><li>a herd of bulls walking through a town guided by men</li><li>a herd of cattle is pushed through a street past people and vendors</li><li>cows walking in a row down an indian street</li><li>a herd of cattle being led down a dirt road</li><li>a bunch of cows are standing in a pin</li></ol></td><td><ol><li>a huge crowd of people gathered around small tents and livestock</li><li>a very large festival in a rural country with man leading cattle</li><li>a crowd of people standing around a herd of cows</li><li>a man pulling two cows by ropes with a lot of people gathered together</li><li>UNK and animals standing around a campground near a city</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000077693.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000378214.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000407590.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000031471.jpg\" ></img></td></tr><tr><td><ol><li>people walking sheep around a grassy area with people watching</li><li>a group of sheep inside of a fenced area</li><li>people are walking inside a gate with many large sheep near an audience</li><li>a crowd of people standing around a field with sheep</li><li>people walking UNK on leashes around in a fenced in area</li></ol></td><td><ol><li>a woman holding a harness on a cow in a festival</li><li>a cow a horse and a sheep with some people</li><li>a person teaching a cow some tricks in a park</li><li>some people that are showing off their animals for a judge to see</li><li>a couple of people on a grassy area with different animals</li></ol></td><td><ol><li>this is a girl feeding an elephant some vegetables</li><li>an elephants trunk taking something from a womans hand</li><li>a young girl feeding an elephant bananas at an animal sanctuary</li><li>some people are feeding some elephants dirt water and trees</li><li>adults interacting with native elephants near river on sunny day</li></ol></td><td><ol><li>a woman tending to a brown cow with a rope wrapped around its mouth</li><li>an adult cow and a baby cow have harnesses on their mouth near a woman</li><li>a woman that is standing next to a cow</li><li>a woman petting a cow that is tied up</li><li>a close up of a woman petting a cow that is tied up</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000048910.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000266273.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000229962.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000332202.jpg\" ></img></td></tr><tr><td><ol><li>a kitchen with a sink a shelf and a chair</li><li>an all white kitchen with a sink and stove</li><li>a kitchen with a shelf cabinets a sink and stove</li><li>a home kitchen with a door leading to the living room</li><li>a narrow kitchen with beams in the ceiling leads to a family room</li></ol></td><td><ol><li>a toddler in a kitchen trying to use a vacuum cleaner</li><li>a mom and a kid in a green kitchen</li><li>a toddler standing around in a kitchen with his mom at the door</li><li>a small boy standing in a kitchen next to a counter</li><li>a mother and baby in the kitchen next to a cabinet and oven</li></ol></td><td><ol><li>a woman standing next to a kitchen sink</li><li>w woman is at the sink in a clean kitchen</li><li>a woman is standing in a kitchen next to the sink</li><li>bright kitchen with woman doing something at the sink</li><li>a person in a very big kitchen by the sink</li></ol></td><td><ol><li>a kitchen filled with appliances and dishes on counters</li><li>a somewhat disorganized looking kitchen with old wooden flooring</li><li>some of the cabinets in the kitchen were left open</li><li>a kitchen has white cabinets and a wood floor</li><li>an l shaped white kitchen with green marble counter tops gets plenty of natural light from</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000409855.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000312850.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000130180.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000553129.jpg\" ></img></td></tr><tr><td><ol><li>a refrigerator that has a microwave above it in the kitchen</li><li>a kitchen with wood cabinets white refrigerator white stove and a microwave above the refrigerator</li><li>microwave sitting inside a wall with a refrigerator</li><li>the kitchen includes a microwave on a refrigerator</li><li>this is the kitchen of a smaller apartment</li></ol></td><td><ol><li>a kitchen with cabinets and sink on the left and fridge on the right</li><li>a kitchen with a large sliding glass door providing a view to a backyard</li><li>a kitchen with a sink oven stove and a refrigerator</li><li>this is a photo of a large kitchen and the door leading in is open</li><li>an empty kitchen with a sliding glass door open</li></ol></td><td><ol><li>a black and white kitchen with an island table area</li><li>a kitchen with a bunch of shelfs in it</li><li>a kitchen that has a black counter top and white cabinets</li><li>this kitchen has all white cabinets and a black stove</li><li>a black stove top oven sitting in a kitchen</li></ol></td><td><ol><li>the organized kitchen of a busy family in a suburban home</li><li>a small kitchen with cupboards an island and fridge</li><li>a messy kitchen with a refrigerator with lots of magnets on the door and a center</li><li>a kitchen has a stainless steel refrigerator and other appliances</li><li>cluttered kitchen with light colored cabinets island and fridge</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000277050.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000184937.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000478675.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000361217.jpg\" ></img></td></tr><tr><td><ol><li>a young lady is looking on while petting an owl</li><li>animal keeper with owl perched on one arm</li><li>a woman holding and petting an owl on a lush green field</li><li>a woman holding an owl on her arm</li><li>a woman outside holding a small owl on her arm</li></ol></td><td><ol><li>a woman is petting a cat and drinking coffee</li><li>a woman sitting on steps petting a cat</li><li>a woman sitting and holding a cup while petting a cat</li><li>a woman holding a beverage petting a cat</li><li>a woman sitting on steps outside is petting a cat</li></ol></td><td><ol><li>a guy holds a cat who is wearing antlers</li><li>man holding a cat that is wearing a costume</li><li>a man is holding a cat in his hands</li><li>a man holding onto a cat and a plant</li><li>there is a man holding a cat but theres something on the cat</li></ol></td><td><ol><li>a couple of pretty young ladies holding kittens</li><li>girls holding kittens while they are being pet</li><li>two women hold cats while others pet the cats</li><li>girls holding kittens in an outdoor space</li><li>girls holding up small white and grey kittens together</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000363321.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000194716.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000169690.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000430394.jpg\" ></img></td></tr><tr><td><ol><li>a little girl is feeding a giraffe at the zoo</li><li>a giraffe licks a girl who is giving it food</li><li>a girl is getting licked by a giraffe in an enclosure</li><li>a close up of a child feeding a giraffe</li><li>a girl leaning on a railing feeding a giraffe</li></ol></td><td><ol><li>a woman holding a small girl with sun glasses on her head</li><li>a smiling young mother holding her infant child</li><li>a woman in sunglasses is outside holding a baby</li><li>a woman holding a baby while she has something in her mouth</li><li>a very attractive woman holding a little girl that is chewing something</li></ol></td><td><ol><li>a little girl sitting on top of a bench in a park</li><li>a young girl in a blue dress with yellow flowers on a bench</li><li>a little girl sitting on a park bench holding a flower</li><li>there is a child that is sitting on the ground</li><li>a girl sitting on a bench holding a flower</li></ol></td><td><ol><li>girl posing for a picture holding a white dog</li><li>a woman is holding a small dog in her arms</li><li>there is a small white dog that has a strip of his hair painted red</li><li>a woman holding a white colored dog with a red dyed mohawk hair style on the</li><li>a woman holding a small white dog</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000012323.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000386560.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000567179.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000208754.jpg\" ></img></td></tr><tr><td><ol><li>a toilet and two rolls of toilet paper in a small room with ledge and window</li><li>a toilet inside a small bathroom being UNK</li><li>a bath room with a toilet and two rolls of toilet paper</li><li>the bathroom with a toilet having an unfinished wall behind it</li><li>a picture of a toilet seat with the lid up in an unfinished bathroom</li></ol></td><td><ol><li>a bathroom with a toilet a roll of UNK and a counter with a missing cabinet</li><li>a bathroom with a toilet and sink sitting on a tiled floor</li><li>a toilet in a bathroom that is being remodeled</li><li>a bathroom toilet with a mirror above and toilet roll</li><li>a single roll of toilet paper sits on top of the toilet tank</li></ol></td><td><ol><li>a bathroom with a toilet sink and toilet paper roll</li><li>a toilet a cabinet a sink a mirror and tan tiles</li><li>a small bathroom with a sink and a toilet</li><li>a bathroom displays a toilet and a sink</li><li>a bathroom with a toilet bowl and sink</li></ol></td><td><ol><li>a young man laying on top of a white toilet seat near a sink</li><li>a toddler playing near the toilet in a bathroom</li><li>a toddler is leaning against a closed toilet</li><li>a little boy playing with a toilet</li><li>a bath room with a toilet and a child on the toilet</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000005277.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000126941.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000472831.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000132454.jpg\" ></img></td></tr><tr><td><ol><li>a white toilet sitting next to a bath tub and a sink</li><li>a small bathroom is shown with a violet shower curtain</li><li>a bathroom is shown with a toilet and sink</li><li>a toilet with a storage cabinet positioned over it next to a sink</li><li>a rest room with a shelf filled with items above a toilet</li></ol></td><td><ol><li>a toilet room in the process of being renovated</li><li>a commode in a bathroom that is in the middle of being remodeled</li><li>an open toilet in a room that is undergoing construction</li><li>there is a toilet that is in the bathroom</li><li>a white toilet sitting inside of a bathroom</li></ol></td><td><ol><li>a white toilet sitting next to a bath tub with a shower curtain over it</li><li>a room showing a toilet and a sink</li><li>a small bathroom with a black and white shower curtain</li><li>a toilet has a shower curtain right next to it</li><li>closed toilet and shower in small bright bathroom</li></ol></td><td><ol><li>an empty bathroom with the toilet lid up</li><li>a toilet and a paper dispenser in a bathroom</li><li>the seat is up on a public toilet</li><li>a mans handicap restroom located in an establishment</li><li>a small restroom with a toilette underneath a paper towel dispenser</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000432201.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000042568.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000229311.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000078266.jpg\" ></img></td></tr><tr><td><ol><li>clean stainless steel kitchen with large cabinets and counter</li><li>a small spotless and clean stainless steel kitchen</li><li>a stainless UNK kitchen with sinks and lots of storage</li><li>a restaurant kitchen stocked with stainless steel appliances</li><li>a kitchen with a sink ovens and dishes in it</li></ol></td><td><ol><li>large shower sectional of a bathroom in a brown and white photograph</li><li>a open shower stall that has a robe next to it</li><li>a bathroom with a stand up shower and tub</li><li>a bathroom with a tub next to a fancy shower stall</li><li>a walk in shower sitting next to a bath tub</li></ol></td><td><ol><li>a stainless steel kitchen sink on a black granite countertop</li><li>a kitchen with a sink on a counter top</li><li>a kitchen with a sink near a window</li><li>a kitchen area with a large stainless steel sink</li><li>an empty kitchen sink underneath a window on the counter</li></ol></td><td><ol><li>kitchen utensils and appliances have been left unattended</li><li>a work room that looks like a dry UNK</li><li>the cramped interior of a passenger ships kitchen</li><li>a room with a bunch of stainless steel items and other accessories</li><li>a clean industrial kitchen with no one in it</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000070434.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000452793.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000504336.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000375728.jpg\" ></img></td></tr><tr><td><ol><li>the bathroom has a sink toilet and glass shower</li><li>a long narrow UNK with a sink mirrors and toilet</li><li>a restroom with a sink mirror and towel</li><li>a narrow bathroom has a long lit hallway</li><li>a bathroom with tall ceilings and an open window on the top</li></ol></td><td><ol><li>a kitchen with a granite counter top and faucet</li><li>a kitchen with a stainless steel fridge and granite counters</li><li>a kitchen with a big fridge and a big sink</li><li>this new fridge goes great in this clean kitchen</li><li>view of kitchen sink stainless refrigerator and breakfast room</li></ol></td><td><ol><li>a large kitchen with extensive counter space and drawers</li><li>a picture of a modern looking empty kitchen</li><li>the kitchen is clean with shiny floors and appliances</li><li>a well lit large open kitchen with wooden cabinets</li><li>a kitchen has a refrigerator a dishwasher and a window</li></ol></td><td><ol><li>a white toilet sitting next to a bathroom sink</li><li>the photo is of a small bathroom with a toilet shower and sink</li><li>a restroom with a toilet and sink</li><li>a bathroom with a glass shower sink and toilet is shown</li><li>a fisheye lens shot of a bathroom with a glass shower stall</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000329755.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000493846.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000016961.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000087920.jpg\" ></img></td></tr><tr><td><ol><li>a man on a bicycle stopped at an intersection</li><li>a man with an orange vest on a bicycle is at an intersection</li><li>a man in an orange vest riding a bike</li><li>man on bike smiling at camera while sitting in intersection</li><li>a man is riding his bike that has packages strapped to the back</li></ol></td><td><ol><li>a man riding a bike down a street past a young man</li><li>an out of shape man rides a bicycle</li><li>an older man is riding his bike down the road</li><li>a person riding a bike on a city street</li><li>an older man riding a bike on a street</li></ol></td><td><ol><li>a guy riding a skateboard on the road with a long pole</li><li>a man long boarding with a stick to propel him</li><li>a man with a stick pushing himself by skateboard</li><li>guy riding skateboard with a long stick while others ride bikes around him</li><li>adult male pushing himself on a skateboard with a stick</li></ol></td><td><ol><li>a lady is riding a bicycle while talking on a cell phone</li><li>a woman rides her bike and talks on the phone</li><li>woman on cell phone bicycling down the street</li><li>a woman on a bike while on a cell phone</li><li>a woman riding a bicycle making a call on the road near a building with cars</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000304134.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000262967.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000489107.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000363455.jpg\" ></img></td></tr><tr><td><ol><li>a bicyclist and pedestrian are approaching an intersection</li><li>a bunch of people at a inter section of a road</li><li>a traffic officer controlling traffic on a busy road</li><li>a traffic officer directs traffic as a woman crosses with a baby</li><li>bicyclists and pedestrians near roadway with adult directing traffic in city area</li></ol></td><td><ol><li>a woman riding a bike down the middle of a street</li><li>a women is riding her bike next to a police officer on a motorcycle down a</li><li>people looking at a scene as a policeman on a motorcycle arrives</li><li>woman on a bike taking a picture of other people</li><li>a group of people on bicycles and motorcycles in a street</li></ol></td><td><ol><li>a man with a hat on riding a bicycle past a man in a guard outfit</li><li>a man travelling on a bicycle with a hat on</li><li>there is a man wearing a hat and riding a bike down the street</li><li>a man wearing a yellow vest is watching a man ride by him on a bike</li><li>a person is riding a bike down the street while a crossing guard is watching</li></ol></td><td><ol><li>a man is riding a bike while holding an umbrella</li><li>a person riding their bicycle in the rain</li><li>a person riding a bike in the rain while holding an umbrella</li><li>a man riding a bike next to another person on a bike</li><li>a person on a bicycle in the rain holding an umbrella</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000037126.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000187972.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000383606.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000134715.jpg\" ></img></td></tr><tr><td><ol><li>camera flash reflected in a mirror in a small tiled bathroom</li><li>flash from camera glares in the mirror above the toilet</li><li>a very small rest room with a toilet and sink</li><li>a bath room with a toilet a sink and a mirror</li><li>a person take a picture of a bathroom</li></ol></td><td><ol><li>a bathroom that has its lights turned on</li><li>a simple modern bathroom is displayed in the dim light</li><li>a bathroom has a window and a glass door</li><li>a modern bathroom offers visitors a touch of privacy during toiletry</li><li>a bathroom that is very white with a light on</li></ol></td><td><ol><li>a blue corner sink with a man reflected in the above mirrors</li><li>a bathroom with a sink and a mirror</li><li>a person taking a picture inside a bathroom with a blue sink and a brown door</li><li>compact hotel bathroom with corner basin and mirrors</li><li>a man holding a camera reflected in a bathroom mirror that sits above a sink and</li></ol></td><td><ol><li>a large mirror above a sink in a bathroom</li><li>a view of a bathroom that looks very elegant</li><li>a bathroom with vanity toilet and tub is decorated in UNK and browns</li><li>a bathroom showing sink toilet and shower</li><li>a shower that has a bar in it</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000491063.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000042086.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000356299.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000303928.jpg\" ></img></td></tr><tr><td><ol><li>the small bathroom as a standing shower stall beside the toilet</li><li>a bathroom with a shower bathtub sink mirror and toilet</li><li>a white toilet and a shower in a room</li><li>the bathroom has a sink and a standup shower in it</li><li>a bathroom with a walk in shower toilet and sink</li></ol></td><td><ol><li>there is a bathroom with a sink tub and shower curtain</li><li>a mirror a sink shower curtains lights and white tiles</li><li>a white sink sitting next to a bath tub in a bathroom</li><li>a bathroom that has a sink and a shower</li><li>a small white sink in a home bathroom</li></ol></td><td><ol><li>a white sink in a bathroom under a mirror</li><li>a bathroom has decorative tile on the floor and is clean</li><li>an inside view of a bathroom with colorful tiling</li><li>a bathroom with a glass shower door a sink and a mirror</li><li>a bath room with a sink a mirror and a shower</li></ol></td><td><ol><li>a walk in shower with a seat next to a white sink</li><li>an standup shower with towels hanging on a rack outside the shower</li><li>a bathroom with a clear glass shower stall</li><li>the corner of a bathroom with a tub and an enclosed glass shower</li><li>a bath room with a stand up shower and a bath tub</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000253528.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000539767.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000135410.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000068789.jpg\" ></img></td></tr><tr><td><ol><li>a row of parking meters sitting next to parked cars</li><li>a row of parking meters along a road</li><li>a sidewalk with many parking meters going all the way down the street</li><li>a boy in red is walking past change meters</li><li>a city street lined with parking meters and parked cars</li></ol></td><td><ol><li>a red bike parked in a parking lot next to buildings</li><li>a view of a parked motorcycle from behind</li><li>a close up of a red parked motorcycle on pavement</li><li>a view of a motorcycle from its back end</li><li>the large motorcycle has two cup holders on it</li></ol></td><td><ol><li>a bike leaning up to a parking meter</li><li>a coin meter that is next to a ladder with balls on it</li><li>a parking meter is on the street in front of a building</li><li>a stack of balls that is next to a parking meter</li><li>a parking meter next to a ladder with bowling balls on each UNK</li></ol></td><td><ol><li>a bunch of cars are passing by a couple meters</li><li>a street wet from rain and crowded with cars</li><li>some parking meters sitting on the side of the road</li><li>a wet street with moving cars parked cars and parking meters</li><li>there are many cars and UNK on this street</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000145039.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000375053.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000302200.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000488367.jpg\" ></img></td></tr><tr><td><ol><li>there is a meter by a car on the side of a road</li><li>a parking meter sitting on the side of a sidewalk</li><li>the parking meter has fifteen minutes let on it</li><li>a parking meter with a blue sticker is on the sidewalk</li><li>a close up of a parking meter on a city street</li></ol></td><td><ol><li>a street scene with focus on a parking meter</li><li>there are many parking meters along this street</li><li>a street with parked cars next to a sidewalk with people walking</li><li>a row of parking meters sitting next to a street</li><li>parking meters and parked cars are lining a street</li></ol></td><td><ol><li>a parking meter sitting in the snow next to a parked car</li><li>a parking meter at a street side with snow around it</li><li>a car is parked on a street next to a parking meter</li><li>a parking meter on the side of a road</li><li>a parking machine that is next to a car</li></ol></td><td><ol><li>a painting sitting on an easel next to a parking meter</li><li>a piece of art is displayed in front of a parking meter</li><li>there is a drawing next to a car timer</li><li>a close up of a painting canvas near a parking meter</li><li>a couple of kids playing off in the back ground</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000515287.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000188343.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000343670.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000474732.jpg\" ></img></td></tr><tr><td><ol><li>a white bathroom with a tub sink and mirror</li><li>a bathroom has a sink and bathtub and open door</li><li>a bathroom scene with photo taken above the bath tub</li><li>a bathroom with a sink and mirror and a bathtub</li><li>a bathroom has a sink and a tub</li></ol></td><td><ol><li>there is a hairdryer mounted on the wall next to the double sink vanity</li><li>the bathroom has two sinks a large mirror and a hair dryer</li><li>a bathroom counter topped with personal care items</li><li>a modern residential bathroom with walk in shower</li><li>a bathroom with double marble sinks is equipped with a wall hanging blow dryer</li></ol></td><td><ol><li>a bathroom with his and her sinks under a large mirror</li><li>two round sinks are in a wooden counter top next to a large mirror</li><li>a shiny white bathroom with a wood decorated counter</li><li>a bathroom with two sinks and a mirror</li><li>the double sink in the bathroom is nice and clean</li></ol></td><td><ol><li>a bathroom with a sink a mirror and a UNK</li><li>a bathroom with a sink mirror and towel rack</li><li>a white sink under a mirror and red walls</li><li>a bathroom with red walls a sink and a table</li><li>a bathroom painted red with a sink and wall light</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000412267.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000175291.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000401458.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000371490.jpg\" ></img></td></tr><tr><td><ol><li>a bathroom that has a larger then normal tub</li><li>a bathroom is shown with a tub and sink</li><li>a bathroom scene with focus on the bathtub</li><li>a large bathroom with a big soaking tub</li><li>a white tub sitting next to a white sink</li></ol></td><td><ol><li>a modern residential bathroom with deep tub toilet and sink</li><li>a bathroom with UNK furnishings in white and tan</li><li>a bathroom with a tub sink toilet and mirror</li><li>a room showing a birth tub and a sink</li><li>a white tub sitting next to a white toilet</li></ol></td><td><ol><li>a bathroom with a white sink underneath a giant vanity mirror</li><li>a large bathroom with some pictures hanging on the wall</li><li>an open bathroom with art on the walls</li><li>a white bathroom trimmed in tan and black with pictures on the wall</li><li>the medium sized bathroom has been decorated with brown curtains</li></ol></td><td><ol><li>the bathtub is across the room from the bathroom sink</li><li>a well cleaned white bathroom with hard floors</li><li>a bathroom scene with just a sink toilet bathtub and wood floors</li><li>a toilet that is next to a bathtub</li><li>a claw foot tub in an old fashioned bathroom</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000358345.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000147196.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000086071.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000424739.jpg\" ></img></td></tr><tr><td><ol><li>a water hydrant on the side of the road</li><li>a dog s diaper is attached to a fire hydrant</li><li>a baby bib hangs on a yellow fire hydrant</li><li>yellow fire hydrant with a babys garment hanging on it</li><li>a fire hydrant with a piece of clothing draped over one edge</li></ol></td><td><ol><li>a green and black fire hydrant with a red top in the dry grass</li><li>a black and white fire hydrant topped with a red ball</li><li>a black and white fire hydrant with a red foam clown nose on top</li><li>a painted fire hydrant sitting in dead grass</li><li>black and white fire hydrant surrounded by dead grass</li></ol></td><td><ol><li>a yellow fire hydrant is sitting on a gravel road</li><li>a yellow fire hydrant sitting next to a red fire hydrant</li><li>the fire hydrant is being capped off by something different</li><li>a yellow fire hydrant in a gravel area</li><li>a fire hydrant is attached to a separated shut off apparatus</li></ol></td><td><ol><li>a tree trunk having some UNK tools and containers resting on top</li><li>camping equipment including a portable stove a UNK and a multi tool</li><li>a large glass jar sitting on top of a wooden table next to construction items</li><li>a knife a lighter and several other UNK items sit on the ground</li><li>items placed on a tree stump for making a cooking stove</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000108602.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000395703.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000052005.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000405630.jpg\" ></img></td></tr><tr><td><ol><li>a skateboard laying on top of a grass covered ground</li><li>a skateboard lays wheels up on the ground as if UNK</li><li>the skateboard is laying upside down in the grass</li><li>an overturned skateboard lying on a grassy field</li><li>an very well used upside down skateboard on grass</li></ol></td><td><ol><li>a yellow fire hydrant laying on its side</li><li>a fire hydrant lies on its side in the street</li><li>a fire hydrant laying on its side out of the ground</li><li>a fire hydrant turned over on its side</li><li>a close up of a fire hydrant laying on the ground</li></ol></td><td><ol><li>the yellow fire hydrant is next to the bushes</li><li>a picture of a fire hydrant next to a plant</li><li>the yellow and black fire hydrant has leaves around it</li><li>a water hydrant sits in front of foliage</li><li>the fire hydrant is yellow and is next to green plants</li></ol></td><td><ol><li>two brightly colored kids bouncy spring rides on a lawn</li><li>the area is outdoors a residential house exterior driveway and yard area while UNK highlighted in</li><li>a ride at a playground made to look like a yellow elephant</li><li>blue and yellow playground toys in the fall</li><li>this ride on toy is in the shape of an elephant</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_neighbors(batch['fc_feats'].numpy(), k=8, num_per_row=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_em(batch, k=5, num_per_row=5, neighbor_type='closest'):\n",
    "    index = loader.indices['train']\n",
    "    for ix in range(len(batch['infos'])):\n",
    "        print(ix)\n",
    "        path = batch['infos'][ix]['file_path']\n",
    "        display_images([path])\n",
    "        target_features = batch['fc_feats'][ix].unsqueeze(0)\n",
    "        neighbor_batch = index.get_neighbor_batch(loader, target_features.numpy(), k, neighbor_type=neighbor_type)\n",
    "        distractor_features = neighbor_batch['fc_feats'][0]\n",
    "        if CUDA:\n",
    "            target_features = target_features.cuda()\n",
    "            distractor_features = distractor_features.cuda()\n",
    "#         cat_feats = torch.cat((target_features.expand_as(distractor_features), distractor_features), -1)\n",
    "#         1 / 0\n",
    "#         scores = model.distractor_scorer.scorer(cat_feats).squeeze(-1).log_softmax(-1)\n",
    "#         scores = model.distractor_scorer(target_features, distractor_features)\n",
    "        scores = ds(target_features, distractor_features)\n",
    "        score_strings = [['{:.4f}'.format(x)] for x in scores.exp().detach().cpu().numpy()]\n",
    "        display_images([d['file_path'] for d in neighbor_batch['infos']], captions=score_strings, num_per_row=5)\n",
    "        print()\n",
    "#     paths_k = [d['file_path'] for d in neighbor_batch['infos']]\n",
    "#     captions_k = [[' '.join(c) for c in ns] for cs in get_captions_from_batch(neighbor_batch) for ns in cs]\n",
    "#     display_images(paths_k, captions=captions_k, num_per_row=num_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_cuda(tensor):\n",
    "    if tensor is None:\n",
    "        return None\n",
    "    if CUDA:\n",
    "        return tensor.cuda()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_em_model(batch, k=5, num_per_row=5, neighbor_type='closest', choose_distractor=False, beam_size=5):\n",
    "    index = loader.indices['train']\n",
    "    opt_new = vars(opt)\n",
    "    assert neighbor_type in ['closest', 'random']\n",
    "    opt_new['pragmatic_distractor_candidate_type'] = neighbor_type\n",
    "    opt_new['pragmatic_distractors'] = k\n",
    "    opt_new['beam_size'] = beam_size\n",
    "    if choose_distractor:\n",
    "        opt_new['pragmatic_distractor_type'] = 'choose_within_closest'\n",
    "    else:\n",
    "        # misnomer; this actually means use all the available distractors\n",
    "        opt_new['pragmatic_distractor_type'] = 'closest'\n",
    "    batch_size = len(batch['infos'])\n",
    "    with torch.no_grad():\n",
    "        fc_feats, att_feats, att_masks = maybe_cuda(batch['fc_feats']), maybe_cuda(batch['att_feats']), maybe_cuda(batch['att_masks'])\n",
    "        model._sample_beam(fc_feats, att_feats, att_masks, opt=opt_new)\n",
    "        beam_captions = [[utils.decode_sequence(model.vocab, _['seq'].unsqueeze(0))[0] for _ in model.done_beams[ix]] for ix in range(batch_size)]\n",
    "        model._sample_contrastive_beam(\n",
    "            fc_feats, att_feats, att_masks,\n",
    "            opt_new,  data=batch, loader=loader, nearest_neighbor_index=index,\n",
    "        )\n",
    "        contrastive_beam_captions = [[utils.decode_sequence(model.vocab, _['seq'].unsqueeze(0))[0] for _ in model.done_beams[ix]] for ix in range(batch_size)]\n",
    "    for ix in range(len(batch['infos'])):\n",
    "        path = batch['infos'][ix]['file_path']\n",
    "        display_images([path, path], captions=[beam_captions[ix], contrastive_beam_captions[ix]], titles=['normal', 'contrastive'])\n",
    "        if hasattr(model, 'dlp'):\n",
    "            scores = model.dlp[ix]\n",
    "            score_strings = ['{:.4f}'.format(x) for x in scores.exp().detach().cpu().numpy()]\n",
    "        else:\n",
    "            score_strings = None\n",
    "        display_images([d['file_path'] for d in model.neighbor_infos[ix]], titles=score_strings, num_per_row=5)\n",
    "        if choose_distractor:\n",
    "            display_images([d['file_path'] for d in model.distractor_infos[ix]], num_per_row=2)\n",
    "        print()\n",
    "#     paths_k = [d['file_path'] for d in neighbor_batch['infos']]\n",
    "#     captions_k = [[' '.join(c) for c in ns] for cs in get_captions_from_batch(neighbor_batch) for ns in cs]\n",
    "#     display_images(paths_k, captions=captions_k, num_per_row=num_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000184613.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000184613.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a group of people standing on top of a lush green field</li><li>a group of people standing on top of a grass covered field</li><li>a group of people standing on top of a field</li><li>a group of people standing next to a herd of sheep</li><li>a group of people standing next to a group of cows</li></ol></td><td><ol><li>a woman holding an umbrella in a field</li><li>a woman holding an umbrella and a cow</li><li>a little girl holding an umbrella in a field</li><li>a little girl holding an umbrella and a cow</li><li>a woman holding an umbrella and a cow in a field</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000250804.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000433662.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000020966.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000063043.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000077693.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000184613.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000250804.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000403013.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000403013.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a kitchen with a stove and a refrigerator</li><li>a kitchen with a stove and a sink</li><li>a kitchen with a refrigerator and a sink</li><li>a kitchen with a refrigerator and a stove</li><li>a kitchen with a stove a sink and a stove</li></ol></td><td><ol><li>a kitchen with a stove and a refrigerator</li><li>a kitchen with a stove and a sink</li><li>a kitchen with a stove a sink and a stove</li><li>a kitchen with a stove a sink and a refrigerator</li><li>a kitchen with a white refrigerator and a stove</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000048910.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000266273.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000229962.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000332202.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000409855.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000403013.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000048910.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000562150.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000562150.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a little girl holding a cat in her hand</li><li>a little girl holding a cat in her lap</li><li>a little girl holding a cat in her hands</li><li>a little girl holding a cat and a cat</li><li>a little girl is holding a cat in her hand</li></ol></td><td><ol><li>a little girl holding a cat on a leash</li><li>a little girl holding a cat in her hand</li><li>a little girl holding a cat in her lap</li><li>a little girl holding a cat in her hands</li><li>a little girl holding a cat and a cat</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000277050.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000184937.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000478675.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000361217.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000363321.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000562150.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000277050.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000360772.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000360772.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a toilet and a sink</li><li>a white toilet sitting in a bathroom next to a sink</li><li>a white toilet sitting next to a bathroom sink</li><li>a white toilet sitting in a bathroom next to a toilet</li><li>a white toilet sitting in a bathroom next to a wall</li></ol></td><td><ol><li>a bathroom with a toilet and a sink</li><li>a white toilet sitting in a bathroom next to a sink</li><li>a bathroom with a toilet and a toilet</li><li>a white toilet sitting in a bathroom next to a wall</li><li>a white toilet sitting next to a bathroom sink</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000012323.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000386560.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000567179.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000208754.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000005277.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000360772.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000012323.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000340559.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000340559.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a kitchen with a sink and a sink</li><li>a bathroom with a sink and a sink</li><li>a kitchen with a sink and a refrigerator</li><li>a kitchen that has a sink and a sink</li><li>a kitchen with a sink a sink and a sink</li></ol></td><td><ol><li>a bathroom with a sink and a sink</li><li>a kitchen with a sink and a sink</li><li>a bathroom with a sink and a sink in it</li><li>a bathroom with a sink a sink and a mirror</li><li>a bathroom with a sink a sink and a sink</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000432201.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000042568.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000229311.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000078266.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000070434.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000340559.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000432201.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000321107.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000321107.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a woman riding a bike down a street</li><li>a man riding a bike down a street</li><li>a person riding a bike down a street</li><li>a woman riding a bicycle down a street</li><li>a woman riding a bike down a street next to a street</li></ol></td><td><ol><li>a woman riding a bike down a street</li><li>a woman riding a bike down the street</li><li>a woman riding a bicycle down a street</li><li>a person riding a bike on a street</li><li>a woman riding a bike down a street next to a street</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000329755.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000493846.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000016961.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000087920.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000304134.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000321107.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000329755.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000129001.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000129001.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a toilet and a sink</li><li>a bath room with a toilet and a sink</li><li>a bathroom with a toilet and a shower</li><li>a bathroom with a toilet sink and shower</li><li>a bath room with a toilet and a shower</li></ol></td><td><ol><li>a bathroom with a toilet and a shower</li><li>a bathroom with a shower and a sink</li><li>a bathroom with a shower and a toilet</li><li>a bath room with a toilet and a shower</li><li>a bath room with a toilet and a sink</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000037126.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000187972.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000383606.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000134715.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000491063.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000129001.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000037126.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000556616.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000556616.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a parking meter on the side of the road</li><li>a parking meter on the side of a street</li><li>a close up of a parking meter on a city street</li><li>a close up of a parking meter on a street</li><li>a parking meter on the side of a road</li></ol></td><td><ol><li>a parking meter on the side of the road</li><li>a parking meter on the side of a street</li><li>a close up of a parking meter on a street</li><li>a close up of a parking meter on a city street</li><li>a parking meter on the side of a road</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000253528.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000539767.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000135410.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000068789.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000145039.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000556616.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000253528.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000472621.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000472621.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a sink and a mirror</li><li>a bathroom with a sink and a sink</li><li>a bathroom with a sink and a tub</li><li>a bath room with a sink and a mirror</li><li>a bathroom that has a sink and a mirror</li></ol></td><td><ol><li>a bathroom with two sinks and a mirror</li><li>a bathroom with a sink and a mirror</li><li>a bathroom with two sinks and a sink</li><li>a bathroom with a sink and a sink</li><li>a bath room with a sink and a mirror</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000515287.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000188343.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000343670.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000474732.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000412267.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000472621.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000515287.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000364521.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000364521.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>there is a banana peel on the ground</li><li>a yellow fire hydrant sitting on the side of a road</li><li>a yellow fire hydrant sitting on the ground</li><li>a yellow fire hydrant sitting on the side of the road</li><li>a yellow fire hydrant sitting on top of a sidewalk</li></ol></td><td><ol><li>there is a banana peel on the ground</li><li>a banana peel sitting on top of a yellow fire hydrant</li><li>a banana sitting on the ground next to a banana</li><li>a banana sitting on the ground next to a fire hydrant</li><li>a banana sitting on the ground next to a yellow fire hydrant</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000358345.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000147196.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000086071.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000424739.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000108602.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000364521.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000358345.jpg\" ></img></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "display_em_model(batch, k=5, neighbor_type='closest', choose_distractor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000184613.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000184613.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a group of people standing on top of a lush green field</li><li>a group of people standing on top of a grass covered field</li><li>a group of people standing on top of a field</li><li>a group of people standing next to a herd of sheep</li><li>a group of people standing next to a group of cows</li></ol></td><td><ol><li>a woman holding an umbrella in a field</li><li>a woman holding an umbrella and a cow</li><li>a little girl holding an umbrella in a field</li><li>a little girl holding an umbrella and a cow</li><li>a woman holding an umbrella and a cow in a field</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000250804.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000433662.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000020966.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000063043.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000077693.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000403013.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000403013.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a kitchen with a stove and a refrigerator</li><li>a kitchen with a stove and a sink</li><li>a kitchen with a refrigerator and a sink</li><li>a kitchen with a refrigerator and a stove</li><li>a kitchen with a stove a sink and a stove</li></ol></td><td><ol><li>a kitchen with a stove and a sink</li><li>a kitchen with a stove and a refrigerator</li><li>a kitchen with a refrigerator and a sink</li><li>a kitchen with a stove a sink and a stove</li><li>a kitchen with a stove a sink and a refrigerator</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000048910.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000266273.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000229962.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000332202.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000409855.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000562150.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000562150.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a little girl holding a cat in her hand</li><li>a little girl holding a cat in her lap</li><li>a little girl holding a cat in her hands</li><li>a little girl holding a cat and a cat</li><li>a little girl is holding a cat in her hand</li></ol></td><td><ol><li>a little girl holding a cat on a leash</li><li>a little girl holding a cat in her hand</li><li>a little girl sitting on a bench with a cat</li><li>a little girl holding a cat in her lap</li><li>a little girl holding a cat and a cat</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000277050.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000184937.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000478675.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000361217.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000363321.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000360772.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000360772.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a toilet and a sink</li><li>a white toilet sitting in a bathroom next to a sink</li><li>a white toilet sitting next to a bathroom sink</li><li>a white toilet sitting in a bathroom next to a toilet</li><li>a white toilet sitting in a bathroom next to a wall</li></ol></td><td><ol><li>a white toilet sitting in a bathroom next to a sink</li><li>a white toilet sitting in a bathroom next to a wall</li><li>a bathroom with a toilet and a sink</li><li>a white toilet sitting in a bathroom next to a window</li><li>a white toilet sitting in a bathroom next to a toilet</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000012323.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000386560.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000567179.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000208754.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000005277.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000340559.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000340559.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a kitchen with a sink and a sink</li><li>a bathroom with a sink and a sink</li><li>a kitchen with a sink and a refrigerator</li><li>a kitchen that has a sink and a sink</li><li>a kitchen with a sink a sink and a sink</li></ol></td><td><ol><li>a stainless steel refrigerator in a small kitchen</li><li>a kitchen with a sink and a sink</li><li>a stainless steel bathroom with a sink and a sink</li><li>a stainless steel bathroom with a sink and a</li><li>a stainless steel refrigerator in a kitchen with a sink</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000432201.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000042568.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000229311.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000078266.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000070434.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000321107.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000321107.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a woman riding a bike down a street</li><li>a man riding a bike down a street</li><li>a person riding a bike down a street</li><li>a woman riding a bicycle down a street</li><li>a woman riding a bike down a street next to a street</li></ol></td><td><ol><li>a woman riding a bike down a street</li><li>a woman riding a bicycle down a street</li><li>a woman riding a bike down the street</li><li>a person riding a bike down a street</li><li>a woman riding a bike down a street next to a street</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000329755.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000493846.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000016961.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000087920.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000304134.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000129001.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000129001.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a toilet and a sink</li><li>a bath room with a toilet and a sink</li><li>a bathroom with a toilet and a shower</li><li>a bathroom with a toilet sink and shower</li><li>a bath room with a toilet and a shower</li></ol></td><td><ol><li>a bathroom with a toilet and a shower</li><li>a bathroom with a toilet and a tub</li><li>a bathroom with a blue and white shower curtain</li><li>a bath room with a toilet and a sink</li><li>a bath room with a toilet and a shower</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000037126.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000187972.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000383606.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000134715.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000491063.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000556616.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000556616.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a parking meter on the side of the road</li><li>a parking meter on the side of a street</li><li>a close up of a parking meter on a city street</li><li>a close up of a parking meter on a street</li><li>a parking meter on the side of a road</li></ol></td><td><ol><li>a row of parking meters on a city street</li><li>a row of parking meters on a street</li><li>a close up of a parking meter on a city street</li><li>a close up of a parking meter on a street</li><li>a close up of a parking meter in a parking lot</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000253528.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000539767.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000135410.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000068789.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000145039.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000472621.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000472621.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>a bathroom with a sink and a mirror</li><li>a bathroom with a sink and a sink</li><li>a bathroom with a sink and a tub</li><li>a bath room with a sink and a mirror</li><li>a bathroom that has a sink and a mirror</li></ol></td><td><ol><li>a bathroom with a tub sink and mirror</li><li>a bathroom with a sink and a tub</li><li>a bath room with a sink and a mirror</li><li>a bath room with a sink and a sink</li><li>a bath room with a sink and a tub</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000515287.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000188343.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000343670.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000474732.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000412267.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000364521.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000364521.jpg\" ></img></td></tr><tr><td><b>normal</b></td><td><b>contrastive</b></td></tr><tr><td><ol><li>there is a banana peel on the ground</li><li>a yellow fire hydrant sitting on the side of a road</li><li>a yellow fire hydrant sitting on the ground</li><li>a yellow fire hydrant sitting on the side of the road</li><li>a yellow fire hydrant sitting on top of a sidewalk</li></ol></td><td><ol><li>there is a banana peel on the ground</li><li>a banana peel sitting on top of a yellow fire hydrant</li><li>a banana sitting on the ground next to a banana</li><li>a banana sitting on the ground next to a fire hydrant</li><li>a banana sitting on the ground next to a yellow fire hydrant</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000358345.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000147196.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000086071.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000424739.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000108602.jpg\" ></img></td></tr><tr><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td><td><b>0.2000</b></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "display_em_model(batch, k=5, neighbor_type='closest', choose_distractor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'UpDownModel' object has no attribute 'distractor_infos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8cc31a34f81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistractor_infos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/image_captioning_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'UpDownModel' object has no attribute 'distractor_infos'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/dfried/miniconda3/envs/image_captioning_pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m(585)\u001b[0;36m__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    583 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    584 \u001b[0;31m        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "\u001b[0m\u001b[0;32m--> 585 \u001b[0;31m            type(self).__name__, name))\n",
      "\u001b[0m\u001b[0;32m    586 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    587 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> \n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "model.distractor_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'ix': tensor(37203),\n",
       "   'id': 250804,\n",
       "   'file_path': 'val2014/COCO_val2014_000000250804.jpg'}],\n",
       " [{'ix': tensor(72565),\n",
       "   'id': 20966,\n",
       "   'file_path': 'train2014/COCO_train2014_000000020966.jpg'}],\n",
       " [{'ix': tensor(45832),\n",
       "   'id': 77693,\n",
       "   'file_path': 'train2014/COCO_train2014_000000077693.jpg'}],\n",
       " [{'ix': tensor(7200),\n",
       "   'id': 48910,\n",
       "   'file_path': 'val2014/COCO_val2014_000000048910.jpg'}],\n",
       " [{'ix': tensor(56906),\n",
       "   'id': 229962,\n",
       "   'file_path': 'train2014/COCO_train2014_000000229962.jpg'}],\n",
       " [{'ix': tensor(9233),\n",
       "   'id': 409855,\n",
       "   'file_path': 'val2014/COCO_val2014_000000409855.jpg'}],\n",
       " [{'ix': tensor(97177),\n",
       "   'id': 277050,\n",
       "   'file_path': 'train2014/COCO_train2014_000000277050.jpg'}],\n",
       " [{'ix': tensor(54246),\n",
       "   'id': 478675,\n",
       "   'file_path': 'train2014/COCO_train2014_000000478675.jpg'}],\n",
       " [{'ix': tensor(19456),\n",
       "   'id': 363321,\n",
       "   'file_path': 'val2014/COCO_val2014_000000363321.jpg'}],\n",
       " [{'ix': tensor(2100),\n",
       "   'id': 12323,\n",
       "   'file_path': 'val2014/COCO_val2014_000000012323.jpg'}]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neighbor_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6026, 0.6102, 0.6137, 0.5967, 0.6030, 0.6111, 0.6166, 0.6101, 0.6100,\n",
       "        0.5992, 0.6018, 0.6147, 0.5993, 0.6145, 0.6118, 0.6105, 0.6007, 0.6031,\n",
       "        0.6045, 0.5957, 0.6020, 0.6081, 0.6077, 0.6051, 0.5998, 1.1390, 0.6043,\n",
       "        0.6162, 0.6023, 0.6040, 0.6152, 0.6034, 0.6006, 0.5940, 0.7514, 0.5928,\n",
       "        0.6147, 0.6074, 0.6116, 0.6148, 0.6010, 0.6115, 0.6109, 0.6097, 0.6141,\n",
       "        0.6119, 0.5952, 0.6209, 0.6084, 0.5976, 0.6089, 0.6116, 0.6126, 0.6000,\n",
       "        0.6146, 0.6141, 0.6067, 0.6163, 0.6192, 0.5979, 0.5961, 0.6064, 0.6114,\n",
       "        0.5971, 0.5947, 0.6004, 0.5953, 0.6098, 0.6064, 1.0470, 0.6025, 0.6158,\n",
       "        0.6044, 0.6151, 0.6055, 0.5994, 0.6419, 0.6100, 0.6038, 0.6050, 0.5956,\n",
       "        0.5979, 0.6115, 0.6025, 0.6198, 0.5984, 0.6649, 1.1684, 0.5947, 0.6083,\n",
       "        0.6156, 0.6136, 0.6199, 0.5962, 0.6016, 0.6144, 0.6130, 0.6060, 0.6106,\n",
       "        0.6102, 0.5972, 0.6144, 0.6051, 0.5952, 0.6119, 0.6029, 0.6189, 0.6045,\n",
       "        0.6128, 0.6073, 0.6073, 0.5941, 0.6012, 0.6087, 0.5982, 0.6013, 0.6170,\n",
       "        0.5959, 0.6058, 0.6011, 0.6105, 0.6018, 0.6022, 0.6081, 0.6057, 0.6164,\n",
       "        0.6015, 0.5856, 0.6123, 0.6113, 0.6048, 0.6076, 0.6005, 0.6055, 0.6093,\n",
       "        0.6025, 0.6044, 0.6135, 0.5883, 0.6087, 0.6013, 0.6084, 0.6093, 0.6103,\n",
       "        0.6054, 0.6076, 0.6183, 0.6172, 0.6156, 0.6143, 0.6063, 0.6060, 0.6145,\n",
       "        0.6059, 0.6052, 0.6103, 0.6066, 0.5959, 0.6201, 0.6028, 1.1274, 0.6013,\n",
       "        0.6628, 0.6179, 0.6182, 0.6109, 0.5970, 0.5988, 0.6009, 0.6096, 0.6001,\n",
       "        0.5944, 0.6005, 0.6223, 0.6017, 0.5897, 0.6107, 0.6041, 0.6043, 0.6109,\n",
       "        0.6085, 0.6019, 0.6056, 0.6137, 0.6182, 0.6016, 0.6407, 0.6185, 0.6073,\n",
       "        0.6119, 0.6120, 0.6124, 0.6050, 0.6095, 0.6249, 0.6138, 0.6054, 0.5960,\n",
       "        0.6028, 0.6101], device='cuda:0', grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distractor_scorer.scorer[0].weight.norm(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_pred_captions = []\n",
    "# for sent in seq:\n",
    "#     this_pred_captions.append([\n",
    "#         [model.vocab.get(str(ix.item()), 'IX_{}'.format(ix.item())) for ix in sent if ix.item() != 0]\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_scores(fc_feats, att_feats, att_masks, seq, add_bos=True):\n",
    "    if add_bos:\n",
    "        seq = torch.cat([torch.zeros(seq.size(0), 1).long().to(seq), seq], 1)\n",
    "    with torch.no_grad():\n",
    "        scores = model(fc_feats, att_feats, seq, att_masks)\n",
    "    mask = (seq[:,:-1] > 0) | (seq[:,1:] > 0)\n",
    "    # TODO: does this include the EOS score?\n",
    "    # seq_t: words input at each position, with 0 for pad\n",
    "    # seq_t: 0, w_0, w_1, w_2, ..., w_k, 0, ...\n",
    "    # mask : 1, 1  , 1  , 1  , 1  , 1  , 0, ...\n",
    "    # selected_scores: w_0 + ... + w_k\n",
    "#     return scores[:,:-1].gather(2, seq[:,1:].unsqueeze(2)).squeeze(2)\n",
    "    selected_scores = (scores[:,:-1].gather(2, seq[:,1:].unsqueeze(2)).squeeze(2) * mask)\n",
    "    return selected_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_product_scores(fc_feats, att_feats, att_masks, seq, add_bos=True):\n",
    "    n_captions = seq.size(0)\n",
    "    n_images = fc_feats.size(0)\n",
    "    assert att_feats.size(0) == n_images\n",
    "    assert att_masks.size(0) == n_images\n",
    "    fc_feats_t = fc_feats.unsqueeze(0).repeat_interleave(n_captions, dim=0)\n",
    "    att_feats_t = att_feats.unsqueeze(0).repeat_interleave(n_captions, dim=0)\n",
    "    att_masks_t = att_masks.unsqueeze(0).repeat_interleave(n_captions, dim=0)\n",
    "    \n",
    "    fc_feats_t = einops.rearrange(fc_feats_t, 'caps imgs d -> (caps imgs) d')\n",
    "    att_feats_t = einops.rearrange(att_feats_t, 'caps imgs obj d -> (caps imgs) obj d')\n",
    "    att_masks_t = einops.rearrange(att_masks_t, 'caps imgs obj -> (caps imgs) obj')\n",
    "    seq_t = seq.unsqueeze(1).repeat_interleave(n_images, dim=1)\n",
    "    seq_t = einops.rearrange(seq_t, 'caps imgs d -> (caps imgs) d')\n",
    "    \n",
    "    scores_per_timestep = caption_scores(fc_feats_t, att_feats_t, att_masks_t, seq_t, add_bos=add_bos)\n",
    "    scores = scores_per_timestep.sum(1)\n",
    "    scores = einops.rearrange(scores, '(caps imgs) -> caps imgs', caps=n_captions, imgs=n_images)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.reset_iterator('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.get_batch('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_feats = data['fc_feats']\n",
    "this_ixs = [d['ix'] for d in data['infos']]\n",
    "this_ids = [d['id'] for d in data['infos']]\n",
    "this_paths = [d['file_path'] for d in data['infos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_trace()\n",
    "sample_n = 10\n",
    "input_data = data['fc_feats'].cuda(), data['att_feats'].cuda(), data['att_masks'].cuda(), data\n",
    "n_predictions = []\n",
    "eval_kwargs = {\n",
    "    'sample_n_method': 'bs',\n",
    "    'sample_n': sample_n,\n",
    "    'temperature': 0.25,\n",
    "    'verbose': False,\n",
    "}\n",
    "eval_utils.eval_split_n(model, n_predictions, input_data=input_data, eval_kwargs=eval_kwargs)\n",
    "captions_by_id = {}\n",
    "log_prob_by_id = {}\n",
    "seq_by_id = {}\n",
    "for k, ds in groupby(n_predictions, lambda d: d['image_id']):\n",
    "    ds = list(ds)\n",
    "    captions_by_id[k] = [d['caption'] for d in ds]\n",
    "    log_prob_by_id[k] = [d['log_prob'] for d in ds]\n",
    "    seq_by_id[k] = [d['seq'] for d in ds]\n",
    "this_captions = [\n",
    "    captions_by_id[id_]  for id_ in this_ids\n",
    "]\n",
    "this_log_probs = [\n",
    "    log_prob_by_id[id_] for id_ in this_ids\n",
    "]\n",
    "this_seq = [\n",
    "    torch.stack(seq_by_id[id_], 0) for id_ in this_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000009426.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000009426.jpg\" ></img></td></tr><tr><td><ol><li>a red and white airplane flying in the sky  -5.3846</li><li>a red and white plane flying in the sky  -5.6425</li><li>a red and white airplane flying in the air  -6.2955</li><li>a red and white airplane flying through a blue sky  -6.4906</li><li>a red and white airplane flying in a blue sky  -6.7558</li><li>a red and white plane flying in a blue sky  -6.8799</li><li>the red and white airplane is flying in the sky  -7.9610</li><li>there is a red and white plane flying in the sky  -8.8055</li><li>an airplane flying in the sky with a red tail  -12.0166</li><li>an airplane is flying in the sky with a red tail  -12.4322</li></ol></td><td><ol><li>a red and white airplane flying in a blue sky  -2.2066</li><li>a red and white airplane flying in the sky  -2.2307</li><li>there is a red and white plane flying in the sky  -2.2577</li><li>the red and white airplane is flying in the sky  -2.2766</li><li>an airplane flying in the sky with a red tail  -2.2893</li><li>an airplane is flying in the sky with a red tail  -2.3098</li><li>a red and white plane flying in a blue sky  -2.3132</li><li>a red and white airplane flying in the air  -2.3209</li><li>a red and white airplane flying through a blue sky  -2.4151</li><li>a red and white plane flying in the sky  -2.4287</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000512438.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000183500.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000440786.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000331738.jpg\" ></img></td></tr><tr><td><ol><li>a white and black plane flying with sky in background</li><li>a small passenger plane flying on a sunny day</li><li>a propeller airplane flying under a cloudy blue sky</li><li>looking under an airplane as it flies in the air</li><li>the airplane is flying near the clouds in the sky</li></ol></td><td><ol><li>a person is flying a biplane in the sky</li><li>an old biplane that is flying low for the crowd</li><li>a red and white plane flying through a cloudy sky</li><li>a propeller plane that is flying in the sky</li><li>white and red biplane flying through the air</li></ol></td><td><ol><li>a bed and white propeller plane flying through a blue sky</li><li>a plane in the middle of the air its a propeller plane</li><li>the old plane has been recently painted in red and white</li><li>a very small red and white air plane</li><li>a plane flying in the air on a clear day</li></ol></td><td><ol><li>a yellow and blue biplane flying through the ski</li><li>a small single engine plane in flying in the sky</li><li>a blue red and white airplane is flying</li><li>a small biplane flies through the blue sky</li><li>an old airplane flies through the sky on a nice day</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000295765.jpg\" ></img></td></tr><tr><td><ol><li>an airplane flying through the air on a clear day</li><li>the airplane is flying high in the clear blue sky</li><li>a white airplane with a single propeller and double stacked wings</li><li>a red white and blue airplane flying in the sky</li><li>a small aircraft flying low on a clear sky</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000242139.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000242139.jpg\" ></img></td></tr><tr><td><ol><li>a city street with lots of tall buildings  -7.8097</li><li>a city street with a large building in the background  -10.1655</li><li>a city street with a tall building in the background  -10.6663</li><li>a city street with a large city in the background  -10.7126</li><li>a city street with tall buildings and a large city  -11.6744</li><li>a city street with cars and a tall building  -12.1900</li><li>a city street with tall buildings and a large building  -12.2099</li><li>a city street with tall buildings and a large building in the background  -12.6306</li><li>a city street with cars and people walking on the sidewalk  -13.4368</li><li>a city street with a tall building and a large city  -15.2348</li></ol></td><td><ol><li>a city street with tall buildings and a large building in the background  -1.9513</li><li>a city street with a tall building and a large city  -1.9794</li><li>a city street with tall buildings and a large city  -2.0439</li><li>a city street with tall buildings and a large building  -2.1185</li><li>a city street with a large city in the background  -2.2861</li><li>a city street with a tall building in the background  -2.4150</li><li>a city street with a large building in the background  -2.5029</li><li>a city street with lots of tall buildings  -2.5392</li><li>a city street with cars and a tall building  -2.5657</li><li>a city street with cars and people walking on the sidewalk  -3.1856</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000533739.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000219750.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000230615.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000219225.jpg\" ></img></td></tr><tr><td><ol><li>heavy traffic in a city with a UNK bank building</li><li>a busy downtown street is filled with cars waiting to move</li><li>a green light is shown on this busy multi lane street</li><li>there are many tall buildings and cars in this city</li><li>a large city with UNK buildings and a green light</li></ol></td><td><ol><li>a red and yellow double decker bus on street next to trees</li><li>a double deck tour bus riding down a street through a traffic light</li><li>a large red bus driving down the street</li><li>a double deck bus that is driving down the road</li><li>a red double decker bus driving down a street</li></ol></td><td><ol><li>a man riding down the street in a horse and carriage</li><li>a group of cars parked in a lot</li><li>a horse drawn carriage comes down the street on a clear day</li><li>a horse drawn carriage on a city street</li><li>the cars are sharing the busy road with the horse</li></ol></td><td><ol><li>traffic and people are standing in the downtown area</li><li>a busy 2 way downtown intersection in the city</li><li>there is a very tall tower with a clock on it on this street</li><li>a busy semi busy street with three yellow taxis going down it</li><li>a tall clock tower on a city street near buildings</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000263826.jpg\" ></img></td></tr><tr><td><ol><li>a transit bus moves through a crowded street</li><li>the buses are lined up on the busy street</li><li>view of down town in a city and traffic driving on the opposite side of the</li><li>two public transit buses on a city street</li><li>a picture of an outdoor area that seems great</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000143931.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000143931.jpg\" ></img></td></tr><tr><td><ol><li>a bus with a advertisement on the side of it  -9.9457</li><li>a truck with a mural on the side of it  -10.0262</li><li>a bus with a mural on the side of it  -10.1005</li><li>a blue truck with a advertisement on the side of it  -10.2522</li><li>a blue bus with a advertisement on the side of it  -10.5892</li><li>a blue truck with a sign on the side of it  -11.0073</li><li>a bus with a large advertisement on the side of it  -11.2638</li><li>a blue truck with a blue and white bus  -14.9023</li><li>a blue truck with a blue and white bus on the side  -16.5830</li><li>a blue truck with a blue and white bus on the side of it  -17.4545</li></ol></td><td><ol><li>a blue truck with a advertisement on the side of it  -1.9789</li><li>a blue truck with a blue and white bus on the side of it  -2.0041</li><li>a blue truck with a blue and white bus on the side  -2.0087</li><li>a blue truck with a blue and white bus  -2.1525</li><li>a truck with a mural on the side of it  -2.2120</li><li>a blue truck with a sign on the side of it  -2.2145</li><li>a blue bus with a advertisement on the side of it  -2.3565</li><li>a bus with a mural on the side of it  -2.7477</li><li>a bus with a large advertisement on the side of it  -2.9925</li><li>a bus with a advertisement on the side of it  -3.0165</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000550874.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000381759.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000048196.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000382854.jpg\" ></img></td></tr><tr><td><ol><li>a bus that is sitting in the street with its door open</li><li>a bus traveling down the street in a city</li><li>the political tour bus serves as home base during the UNK</li><li>a bus decorated for a presidential political campaign</li><li>a bus for a politician driving down the street</li></ol></td><td><ol><li>a large truck driving down a busy street filled with traffic</li><li>a refrigerated semi truck drives on a rode beside a smaller car</li><li>the semi truck and car turn the corner close to each other</li><li>small car rides behind a large semi truck with a large bed</li><li>a car and truck are navigating a turn together</li></ol></td><td><ol><li>a long yellow bus advertising a musical play</li><li>a yellow bus with a lion king ad on it</li><li>a large yellow bus with pictures of people in lion costumes and the words the lion</li><li>a bus is covered in an advertisement for a broadway show</li><li>a bus with advertisement painted on the side</li></ol></td><td><ol><li>a black bus on street with flags and buildings in background</li><li>a black bus driving down the road in the middle of the city</li><li>the team bus is parked at the building</li><li>the large tour bus is painted with a dog mascot</li><li>a large black truck driving down a city street</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000514801.jpg\" ></img></td></tr><tr><td><ol><li>a vehicle pulls up next to a building</li><li>the large blue truck is parked at the curb</li><li>a truck that is driving on the road</li><li>a large blue tow truck sitting on the side of a road</li><li>a truck is on the city street</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000040102.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000040102.jpg\" ></img></td></tr><tr><td><ol><li>a couple of giraffe standing next to each other  -5.7969</li><li>a couple of giraffe standing on top of a lush green field  -6.3289</li><li>a couple of giraffes are standing in a field  -6.6013</li><li>a couple of giraffe standing next to each other on a field  -6.6032</li><li>two giraffes are standing in a grassy field  -6.6232</li><li>two giraffes standing in the grass near trees  -7.4514</li><li>two giraffes standing in a field of grass  -8.3326</li><li>two giraffes standing in a grassy field next to trees  -8.4241</li><li>two giraffes standing in a field with trees  -8.5482</li><li>two giraffes standing in a grassy field with trees  -8.6169</li></ol></td><td><ol><li>two giraffes standing in a grassy field with trees  -1.8652</li><li>two giraffes standing in the grass near trees  -1.9938</li><li>two giraffes are standing in a grassy field  -2.0416</li><li>two giraffes standing in a grassy field next to trees  -2.0757</li><li>two giraffes standing in a field of grass  -2.2234</li><li>two giraffes standing in a field with trees  -2.2874</li><li>a couple of giraffe standing on top of a lush green field  -2.4703</li><li>a couple of giraffes are standing in a field  -2.8429</li><li>a couple of giraffe standing next to each other  -2.9213</li><li>a couple of giraffe standing next to each other on a field  -3.0531</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000238713.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000022257.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000508969.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000172426.jpg\" ></img></td></tr><tr><td><ol><li>a group of zebras on a grassy area next to trees</li><li>a group of giraffes stand next in a field by a tree</li><li>a group of giraffes in a field near trees</li><li>a group of four giraffes standing next to each other</li><li>a herd of giraffe walking across a field</li></ol></td><td><ol><li>a herd of giraffe standing next to each other near a forested hillside</li><li>a group of giraffes are standing together on the UNK</li><li>an image of a herd of giraffes in a plain</li><li>half a dozen healthy giraffes hanging out in a field</li><li>a group of giraffes faces and stare in the same direction while one of the faces</li></ol></td><td><ol><li>the giraffes stood together next to the bush</li><li>two giraffes standing in open field with trees</li><li>two giraffes are heading towards trees for leaves</li><li>one giraffe is behind another giraffe on the grass</li><li>two giraffes stand right next to each other</li></ol></td><td><ol><li>two giraffes walking through a spacious grassy field</li><li>two giraffes that are walking together in a field</li><li>two giraffes next to one another near a rock</li><li>two giraffes standing next to each other under a group of trees</li><li>two giraffes standing on all fours next to one another with grass bushes and trees around</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000257983.jpg\" ></img></td></tr><tr><td><ol><li>several giraffes are standing on the short grass</li><li>group of giraffes standing in grass lands</li><li>adult giraffe surrounded by three younger giraffe in the wild</li><li>the three giraffes are standing in the grassy field together</li><li>some giraffes in a field with trees in the background</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000403020.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000403020.jpg\" ></img></td></tr><tr><td><ol><li>a giraffe is laying down in the dirt  -5.5802</li><li>the giraffe is laying down in the dirt  -6.8027</li><li>a giraffe laying on the ground next to a building  -7.1025</li><li>a giraffe laying down in the dirt near a building  -7.6570</li><li>a giraffe laying down in the dirt next to a building  -8.2647</li><li>a giraffe laying on the ground in a zoo  -8.3065</li><li>a giraffe laying on the ground in a dirt  -8.6407</li><li>a giraffe laying down in the dirt in a zoo  -8.9004</li><li>a giraffe laying down on the ground in a zoo  -9.0528</li><li>a giraffe laying down on the ground in a dirt  -9.4864</li></ol></td><td><ol><li>a giraffe laying down in the dirt near a building  -2.1925</li><li>a giraffe laying down in the dirt next to a building  -2.1933</li><li>a giraffe laying on the ground next to a building  -2.1935</li><li>a giraffe laying down on the ground in a dirt  -2.3129</li><li>the giraffe is laying down in the dirt  -2.3140</li><li>a giraffe laying down on the ground in a zoo  -2.3565</li><li>a giraffe laying on the ground in a dirt  -2.3627</li><li>a giraffe laying down in the dirt in a zoo  -2.3633</li><li>a giraffe laying on the ground in a zoo  -2.3737</li><li>a giraffe is laying down in the dirt  -2.3938</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000050101.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000334957.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000067572.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000476871.jpg\" ></img></td></tr><tr><td><ol><li>four giraffes out in a field of some sort</li><li>three large giraffes with one small standing next to a building</li><li>a group of giraffes in a large enclosure next to a stone barn</li><li>three adult and one baby giraffe standing outside</li><li>a stone barn at a zoo with four giraffe standing around</li></ol></td><td><ol><li>a giraffe kneeling down on the ground next to a tree</li><li>a giraffe on its knees in the sand</li><li>a giraffe whose knees a UNK beneath itself</li><li>a giraffe kneeling down on its front legs on sand in a fenced in area</li><li>a giraffe in a fenced area down on its knees</li></ol></td><td><ol><li>several giraffes are on display in a zoo exhibit</li><li>four giraffes standing and lounging in an enclosure</li><li>the giraffes are standing in the sand beside a fence</li><li>four giraffes standing and sitting in an enclosure</li><li>a herd of giraffe standing around an enclosure at a zoo</li></ol></td><td><ol><li>giraffes standing in a dirt lot near a pool of water</li><li>giraffes in a zoo enclosure with a stone wall</li><li>two giraffes and a rhino in an enclosure</li><li>two giraffes look over a fence in a zoo</li><li>giraffes in an enclosure stand together by the water</li></ol></td></tr><tr><td><img width=300 src=\"val2014/COCO_val2014_000000196650.jpg\" ></img></td></tr><tr><td><ol><li>a giraffe standing next to another animal in a field</li><li>a giraffe and a deer standing near a ravine</li><li>a giraffe doing an odd pose in a field in front of a forest</li><li>a giraffe with its back legs spread while it leans forward</li><li>a giraffe is posing for the camera</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000505440.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000505440.jpg\" ></img></td></tr><tr><td><ol><li>a couple of giraffe standing next to each other  -6.3707</li><li>a couple of giraffe standing on top of a lush green field  -6.4391</li><li>a couple of giraffes are standing in a field  -7.0572</li><li>a couple of giraffe standing next to each other on a lush green field  -7.4226</li><li>two giraffes standing in the grass near trees  -8.1003</li><li>two giraffes standing in a grassy area next to trees  -8.6406</li><li>two giraffes standing in a field next to trees  -9.1155</li><li>two giraffes standing in a field with trees  -9.2221</li><li>two giraffes standing in a grassy field next to trees  -9.4280</li><li>two giraffes standing in a field of grass and trees  -9.8691</li></ol></td><td><ol><li>two giraffes standing in a grassy area next to trees  -1.8909</li><li>two giraffes standing in the grass near trees  -1.9922</li><li>two giraffes standing in a field of grass and trees  -2.0097</li><li>two giraffes standing in a field with trees  -2.1959</li><li>two giraffes standing in a grassy field next to trees  -2.1976</li><li>two giraffes standing in a field next to trees  -2.2443</li><li>a couple of giraffe standing on top of a lush green field  -2.4730</li><li>a couple of giraffe standing next to each other on a lush green field  -2.6140</li><li>a couple of giraffes are standing in a field  -2.8668</li><li>a couple of giraffe standing next to each other  -3.3280</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000340345.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000359189.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000119529.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000444464.jpg\" ></img></td></tr><tr><td><ol><li>a group of giraffe standing next to each other in an open field</li><li>a herd of giraffe standing around a large tree stump</li><li>a group of giraffes are nibbling on a large tree trunk</li><li>group of giraffes outside standing around a stump</li><li>a group of giraffes standing around a short UNK tree</li></ol></td><td><ol><li>three giraffes are standing together surrounded by trees and shrubbery</li><li>a group of three giraffe in the wilderness</li><li>a group of giraffes foraging among the grass</li><li>three giraffes gathered together in their own habitat</li><li>giraffes standing next to each other near a forest</li></ol></td><td><ol><li>three giraffes standing in grass with their heads in a tree</li><li>a group of giraffes standing in front of a tree</li><li>three giraffes who are eating from a large tree</li><li>the three giraffes are standing by the tree</li><li>a family of three giraffes is standing under a big tree</li></ol></td><td><ol><li>a group of giraffe standing on top of a field</li><li>one adult giraffe and two kid giraffes standing in the woods</li><li>giraffes in the wild under trees on a sunny day</li><li>the adult giraffe is in the field feeding with the two offspring</li><li>three giraffes standing in the grass among trees and bushes</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000024095.jpg\" ></img></td></tr><tr><td><ol><li>two giraffe in a wooded area with an orange fence</li><li>two giraffes standing on rocks in the middle of a field</li><li>two giraffes in a wooded and grassy area</li><li>two giraffes standing in a green shady field</li><li>two giraffes standing next to each other in front of trees</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000029913.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000029913.jpg\" ></img></td></tr><tr><td><ol><li>a fire hydrant with a hose attached to it  -7.4004</li><li>a fire hydrant is on the side of the road  -8.1863</li><li>a fire hydrant that is on the side of the road  -8.7289</li><li>a fire hydrant that is on the side of a road  -9.0019</li><li>the fire hydrant is on the side of the road  -9.0924</li><li>a fire hydrant is painted white and blue  -10.1041</li><li>a fire hydrant is painted white and black  -10.1185</li><li>a fire hydrant is on the sidewalk next to a car  -10.4407</li><li>a fire hydrant is on a sidewalk next to a car  -10.7089</li><li>a fire hydrant that has been painted white and blue  -11.2274</li></ol></td><td><ol><li>a fire hydrant is on the sidewalk next to a car  -1.4475</li><li>a fire hydrant is on a sidewalk next to a car  -1.4559</li><li>a fire hydrant with a hose attached to it  -1.5761</li><li>a fire hydrant is painted white and black  -2.6243</li><li>a fire hydrant that has been painted white and blue  -2.8812</li><li>a fire hydrant is on the side of the road  -2.9437</li><li>the fire hydrant is on the side of the road  -3.1696</li><li>a fire hydrant that is on the side of a road  -3.2031</li><li>a fire hydrant that is on the side of the road  -3.2978</li><li>a fire hydrant is painted white and blue  -3.7296</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000328662.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000490887.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000016805.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000236769.jpg\" ></img></td></tr><tr><td><ol><li>a motorcycle parked in a parking lot next to a car</li><li>an antique indian motorcycle is parked next to the sidewalk</li><li>motorcycle parked on the edge of a street</li><li>an old indian motorcycle parked at the curb of a street</li><li>a motorcycle parked on a sidewalk next to a street</li></ol></td><td><ol><li>a motorcycle parked next to a sidewalk on the street</li><li>the motorcycle is parked at the curb near the bicycles</li><li>a street scene with the motorcycle and bicycles on the side of the road</li><li>bicycles and a motorcycle parked on a city sidewalk</li><li>a motorcycle and bicycles parked on a city street</li></ol></td><td><ol><li>the yellow fire hydrant is on the curb as cars pass by</li><li>a yellow fire hydrant sitting on the side of a road</li><li>a yellow fire hydrant next to a street</li><li>a yellow fire hydrant that is on a sidewalk</li><li>a fire hydrant sits next to a city street</li></ol></td><td><ol><li>a red white and blue fire hydrant covered in stars</li><li>the fire hydrant is painted red white and blue</li><li>a close up of a fire hydrant UNK red white and blue with stars</li><li>a fire hydrant painted red white and blue are on the curb</li><li>a fire hydrant painted red white and blue with white stars</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000517835.jpg\" ></img></td></tr><tr><td><ol><li>a hydrant that is sitting on the sidewalk</li><li>a fire hydrant is next to a cone on a sidewalk</li><li>a pipe sticking out of a paved surface next to a street grate</li><li>there is a water hole on the street</li><li>there is construction work being done on an urban street</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000431573.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000431573.jpg\" ></img></td></tr><tr><td><ol><li>a red fire hydrant sitting in the middle of a sidewalk  -7.0782</li><li>a red fire hydrant in front of a tree  -7.2148</li><li>a red fire hydrant in the middle of a park  -7.5111</li><li>a fire hydrant in the middle of a park  -7.6126</li><li>a red fire hydrant in the middle of a sidewalk  -7.9263</li><li>a fire hydrant in the middle of a sidewalk  -8.0315</li><li>a fire hydrant is spraying water onto a street  -8.3755</li><li>a red fire hydrant is in the middle of a sidewalk  -9.2053</li><li>a red fire hydrant in a city street  -9.6061</li><li>a red fire hydrant in a park next to a tree  -10.1319</li></ol></td><td><ol><li>a red fire hydrant in a park next to a tree  -2.0400</li><li>a red fire hydrant in a city street  -2.0684</li><li>a red fire hydrant in front of a tree  -2.0851</li><li>a red fire hydrant is in the middle of a sidewalk  -2.0884</li><li>a red fire hydrant in the middle of a park  -2.0914</li><li>a red fire hydrant in the middle of a sidewalk  -2.1153</li><li>a red fire hydrant sitting in the middle of a sidewalk  -2.1219</li><li>a fire hydrant in the middle of a park  -2.7492</li><li>a fire hydrant in the middle of a sidewalk  -3.1231</li><li>a fire hydrant is spraying water onto a street  -3.7515</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"train2014/COCO_train2014_000000430144.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000148318.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000127455.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000522015.jpg\" ></img></td></tr><tr><td><ol><li>a blue and white fire hydrant on the sidewalk</li><li>a blue and white fire hydrant on the side of the street</li><li>a blue fire hydrant with a white top sits beside a road</li><li>a blue fire hydrant sits in the middle of a sidewalk</li><li>a blue and white fire hydrant sitting on top of a sidewalk</li></ol></td><td><ol><li>a fire hydrant in a city with water pouring out of both sides</li><li>a fire hydrant has water streaming out of two holes on its side</li><li>a green fire hydrant pouring water from two of its spouts</li><li>a fire hydrant that is open with water coming out of two holes</li><li>a fire hydrant with water pouring out of it</li></ol></td><td><ol><li>a fire hydrant next to a bush at a park</li><li>a parking meter on the side of a wooded street</li><li>a fire hydrant on a neighborhood street with trees and shrubs around it</li><li>a street corner with a blue fire hydrant</li><li>a scenic view of a wooded area with parking meter</li></ol></td><td><ol><li>a blue and pink fire hydrant spewing out water onto a street</li><li>a fire hydrant open spilling water onto the street</li><li>a pink faded fire hydrant with dirty water coming out of it</li><li>a fire hydrant is open with water coming out</li><li>open fire hydrant with warning cone in urban city setting</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000536884.jpg\" ></img></td></tr><tr><td><ol><li>a fire hydrant on the corner of a neighborhood street</li><li>a fire hydrant on the corner of a street</li><li>a yellow and green fire hydrant sitting on the side of a road</li><li>the fire hydrant is green and yellow</li><li>a fire hydrant sitting near a sign beside the street</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000332654.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000332654.jpg\" ></img></td></tr><tr><td><ol><li>a yellow and blue fire hydrant sitting on the side of a road  -4.9590</li><li>a yellow fire hydrant sitting on the side of a road  -5.1579</li><li>a blue and yellow fire hydrant sitting on the side of a road  -5.4978</li><li>a yellow and blue fire hydrant on a sidewalk  -5.8938</li><li>a blue and yellow fire hydrant on a sidewalk  -6.5236</li><li>the fire hydrant is on the side of the road  -8.2083</li><li>a fire hydrant on a sidewalk next to a street  -8.2193</li><li>a yellow fire hydrant on a sidewalk next to a street  -8.2990</li><li>a fire hydrant on a sidewalk near a street  -8.3000</li><li>a yellow fire hydrant on a sidewalk near a street  -8.9389</li></ol></td><td><ol><li>a blue and yellow fire hydrant sitting on the side of a road  -1.7379</li><li>a blue and yellow fire hydrant on a sidewalk  -1.9939</li><li>a yellow and blue fire hydrant sitting on the side of a road  -2.1876</li><li>a yellow fire hydrant sitting on the side of a road  -2.2820</li><li>a yellow fire hydrant on a sidewalk near a street  -2.4456</li><li>a yellow fire hydrant on a sidewalk next to a street  -2.4725</li><li>a yellow and blue fire hydrant on a sidewalk  -2.5455</li><li>a fire hydrant on a sidewalk next to a street  -2.5564</li><li>the fire hydrant is on the side of the road  -2.5935</li><li>a fire hydrant on a sidewalk near a street  -2.6334</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000338560.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000532482.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000190664.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000316993.jpg\" ></img></td></tr><tr><td><ol><li>a blue fire hydrant posed on a street corner in a city</li><li>a blue water hydrant on a pavement near the road</li><li>a blue and yellow fire hydrant sitting on the sidewalk next to a quiet street</li><li>a blue and yellow fire hydrant on the side of a road</li><li>a fire hydrant on a sidewalk of a city</li></ol></td><td><ol><li>a green fire hydrant with three yellow concrete barriers around it</li><li>pavement level view of green hydrant near a street corner</li><li>a green fire hydrant surrounded by three yellow poles</li><li>a green fire hydrant sitting between three yellow post</li><li>a green fire hydrant and a bus on the road</li></ol></td><td><ol><li>a fire hydrant that is sitting on the sidewalk</li><li>an orange fire hydrant near the side of the street</li><li>an orange fire hydrant sitting at the side of the street</li><li>a fire hydrant on a sidewalk next to a street</li><li>a UNK hydrant on a side walk near a city street</li></ol></td><td><ol><li>a street intersection that has a traffic light and a direction sign on the corner along</li><li>there is a telescope in the middle of a street</li><li>a street sign near a traffic light pole</li><li>that is a picture of an outside region</li><li>a closeup of a telescope next to a street</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000336040.jpg\" ></img></td></tr><tr><td><ol><li>a fire hydrant is painted silver and blue</li><li>two fire hydrants that are by the street</li><li>two silver and blue fire hydrants side on either side of a road</li><li>silver and blue fire hydrants are placed parallel to each other</li><li>a fire hydrant is painted blue and grey</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000176649.jpg\" ></img></td><td><img width=300 src=\"val2014/COCO_val2014_000000176649.jpg\" ></img></td></tr><tr><td><ol><li>a close up of a street sign with a sky background  -5.2408</li><li>a street sign that is on a pole  -9.8394</li><li>a street sign with a sticker on it  -10.0734</li><li>a street sign that says UNK and UNK  -11.1867</li><li>a street sign with a sign on it  -12.2090</li><li>a street sign with a sign that reads UNK  -13.1063</li><li>a sign that says UNK and UNK UNK  -13.5002</li><li>a street sign with a sign that says UNK  -13.5340</li><li>a street sign with a sticker of a man on it  -14.0173</li><li>a sign that says UNK UNK and a street  -15.6800</li></ol></td><td><ol><li>a sign that says UNK UNK and a street  -1.8236</li><li>a street sign with a sticker of a man on it  -2.0566</li><li>a sign that says UNK and UNK UNK  -2.0826</li><li>a close up of a street sign with a sky background  -2.1726</li><li>a street sign with a sticker on it  -2.3357</li><li>a street sign with a sign that says UNK  -2.3788</li><li>a street sign with a sign that reads UNK  -2.3977</li><li>a street sign that is on a pole  -2.7060</li><li>a street sign with a sign on it  -2.7338</li><li>a street sign that says UNK and UNK  -2.8123</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td><img width=300 src=\"val2014/COCO_val2014_000000136411.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000112207.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000037458.jpg\" ></img></td><td><img width=300 src=\"train2014/COCO_train2014_000000247547.jpg\" ></img></td></tr><tr><td><ol><li>a stop sign with graffiti on the UNK block of UNK street</li><li>a close up of a vandalized stop sign on a pole</li><li>a stop sign and street sign attached to a pole at an intersection</li><li>a stop sign on UNK street has graffiti</li><li>stop sign with intended UNK written in below it</li></ol></td><td><ol><li>a sign prohibiting bicycle parking with UNK of towing</li><li>a sign indicating that bicycle parking is not allowed</li><li>a red and white street sign stating no bicycle parking</li><li>a picture of a no bicycle parking sign</li><li>a street sign that tells UNK not to park</li></ol></td><td><ol><li>a black and white street sign that reads end bird</li><li>looking up at a street sign that reads end bird</li><li>sign on a street pole saying end bird</li><li>a street sign stands under some power lines</li><li>a sign on a post that reads end bird on it</li></ol></td><td><ol><li>a red stop sign with the word them under it</li><li>a one way sign is attached to a stop sign</li><li>a stop sign with the word stop them on it below a one way</li><li>a stop sign vandalized to read stop them</li><li>a street stop sign with a one way sign attached on top</li></ol></td></tr><tr><td><img width=300 src=\"train2014/COCO_train2014_000000389190.jpg\" ></img></td></tr><tr><td><ol><li>a red sign warning people about pedestrians UNK hit by a crossing guard</li><li>a round red danger railroad crossing sign with a red umbrella in the background</li><li>a warning sign about danger at a railroad crossing</li><li>a sign show that there is danger ahead</li><li>a red danger sign with a person on it</li></ol></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "for i in range(10):\n",
    "    caps = this_captions[i]\n",
    "#     this_s0_scores = this_log_probs[i]\n",
    "    seq = this_seq[i]\n",
    "    neighbor_batch = get_neighbor_batch(this_feats[i].numpy(), K, include_self=True, self_ix=this_ixs[i])\n",
    "    \n",
    "    # num_sampled_captions x (1+K)\n",
    "    cp_scores = cross_product_scores(\n",
    "        neighbor_batch['fc_feats'].cuda(),\n",
    "        neighbor_batch['att_feats'].cuda(), \n",
    "        neighbor_batch['att_masks'].cuda(),\n",
    "        this_seq[i].cuda()\n",
    "    )\n",
    "    this_s0_scores = cp_scores[:,0].detach().cpu().tolist()\n",
    "    \n",
    "    l1_scores = cp_scores.log_softmax(1)\n",
    "    s1_scores = l1_scores.log_softmax(0)\n",
    "    \n",
    "    this_s1_scores = s1_scores[:,0].detach().cpu().tolist()\n",
    "    \n",
    "    def make_strings(lps, caps):\n",
    "        scored_caps = sorted(list(zip(lps, caps)), reverse=True)\n",
    "        deduped_caps = [next(g) for k, g in groupby(scored_caps, lambda t: t[1])]\n",
    "        cap_strings = [\"{}  {:.4f}\".format(cap, lp) for lp, cap in deduped_caps]\n",
    "        return cap_strings\n",
    "    \n",
    "    display_images([this_paths[i], this_paths[i]], \n",
    "                   captions=[\n",
    "                       make_strings(this_s0_scores, caps)[:10],\n",
    "                       make_strings(this_s1_scores, caps)[:10],\n",
    "                   ])\n",
    "    display_neighbors(data['fc_feats'][i].numpy(), k=min(K, 12), num_per_row=4)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
